{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tut5 - RNN with variable length seqs\n",
    "\n",
    "From: https://gist.github.com/evanthebouncy/8e16148687e807a46e3f#file-tensorflow-rnn-variable-seq-length\n",
    "https://www.reddit.com/r/MachineLearning/comments/3sok8k/tensorflow_basic_rnn_example_with_variable_length/\n",
    "\n",
    "There are some comments in the link (reproduced below)\n",
    "\n",
    "Actually, it did as intended.\n",
    "\n",
    "\n",
    "#### Original Comments:\n",
    "\n",
    "I've finally gotten a chance to look at recurrence in tensorflow, the documentation examples are a bit complicated for understanding the bare bones of what is happening. This is the basic example I've come up with for just passing some data through a LSTM with no learning going on, its useful for understanding how to set things up.\n",
    "\n",
    "My takeaways from writing this are:\n",
    "- Getting the inputs in is a little weird, since the recurrence loop is built with a python loop. Because of this I had to define the input, then use tf.split to break it into discrete timesteps. Split also keeps the dimension you split on, so there is a reshape in there as well. If you aren't comfortable with list comprehension, it feels like something you will want to bone up on for TF.\n",
    "- Variable initialization is an operation you run, not a function you call. This threw me off (coming from theano), I assumed tf.initialize_all_variables() was what I needed, but you have to actually pass that into the session. Makes sense in hindsight.\n",
    "- Conditionals aren't documented at all on the tensorflow website, but are in the library. This is how we 'bail' from the recurrent loop for variable length sequences. check out rnn.py for how it is used in action. Same idea as theano's ifelse.\n",
    "- For variable length sequences you will need to build the graph out to the maximum length you want to support, then exit early during runtime. You can pass in the bail point for your sequence at each .run() call, since the conditional check is in tensorflow and not python.\n",
    "- You are going to need to pad your input to the maximum size of the loop. I didn't play with tf.pad enough to figure out if you can actually pass in variable length sequences to the .run() call, but the inputs you pass to the rnn when constructing it needs to be the maximum length so I had to make the placeholder that long. Worst case is you will need to pad your data before passing it into .run(), I assume the pain of this is lessened with the Queue setup that is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf    \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.LSTMCell object at 0x10ee24470>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.LSTMCell object at 0x10ee24470>: The input_size parameter is deprecated.\n"
     ]
    }
   ],
   "source": [
    "#if __name__ == '__main__':\n",
    "np.random.seed(1)  \n",
    "# the size of the hidden state for the lstm (notice the lstm uses 2x of this amount so actually lstm will have state of size 2)\n",
    "size = 1\n",
    "# 2 different sequences total\n",
    "batch_size= 2\n",
    "# the maximum steps for both sequences is 10\n",
    "n_steps = 10\n",
    "# each element of the sequence has dimension of 2\n",
    "seq_width = 2\n",
    "\n",
    "# the first input is to be stopped at 4 steps, the second at 6 steps\n",
    "e_stop = np.array([4,6])\n",
    "\n",
    "initializer = tf.random_uniform_initializer(-1,1) \n",
    "\n",
    "# the sequences, has n steps of maximum size\n",
    "seq_input = tf.placeholder(tf.float32, [n_steps, batch_size, seq_width])\n",
    "# what timesteps we want to stop at, notice it's different for each batch hence dimension of [batch]\n",
    "early_stop = tf.placeholder(tf.int32, [batch_size])\n",
    "\n",
    "# inputs for rnn needs to be a list, each item being a timestep. \n",
    "# we need to split our input into each timestep, and reshape it because split keeps dims by default  \n",
    "inputs = [tf.reshape(i, (batch_size, seq_width)) for i in tf.split(0, n_steps, seq_input)]\n",
    "\n",
    "cell = tf.nn.rnn_cell.LSTMCell(size, seq_width, initializer=initializer)  \n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "# ========= This is the most important part ==========\n",
    "# output will be of length 4 and 6\n",
    "# the state is the final state at termination (stopped at step 4 and 6)  \n",
    "outputs, state = tf.nn.rnn(cell, inputs, initial_state=initial_state, sequence_length=early_stop)\n",
    "\n",
    "# usual crap\n",
    "iop = tf.initialize_all_variables()\n",
    "session = tf.Session()\n",
    "session.run(iop)\n",
    "feed = {early_stop:e_stop, seq_input:np.random.rand(n_steps, batch_size, seq_width).astype('float32')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret this:\n",
    "- there will be two outputs.\n",
    "- the total length will be n_steps = 10\n",
    "- however, one of the seqs will stop at 6 and another at 4, and it will be filled/padded by zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs, should be 2 things one of length 4 and other of 6\n",
      "0: [[ 0.04543639]\n",
      " [ 0.03712803]]\n",
      "1: [[ 0.02025254]\n",
      " [ 0.05193096]]\n",
      "2: [[ 0.04791925]\n",
      " [ 0.08056492]]\n",
      "3: [[ 0.09846628]\n",
      " [ 0.11049453]]\n",
      "4: [[ 0.        ]\n",
      " [ 0.07409128]]\n",
      "5: [[ 0.        ]\n",
      " [ 0.10492748]]\n",
      "6: [[ 0.]\n",
      " [ 0.]]\n",
      "7: [[ 0.]\n",
      " [ 0.]]\n",
      "8: [[ 0.]\n",
      " [ 0.]]\n",
      "9: [[ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"outputs, should be 2 things one of length 4 and other of 6\")\n",
    "outs = session.run(outputs, feed_dict=feed)\n",
    "for i,x in enumerate(outs):`\n",
    "    print(\"{}: {}\".format(i,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states, 2 things total both of size 2, which is the size of the hidden state\n",
      "[[ 0.16851933  0.09846628]\n",
      " [ 0.17804879  0.10492748]]\n"
     ]
    }
   ],
   "source": [
    "print(\"states, 2 things total both of size 2, which is the size of the hidden state\")\n",
    "st = session.run(state, feed_dict=feed)\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
